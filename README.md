# Kafka-4-noobs [WIP] 
Este repositÃ³rio tem como objetivo servir de ajuda e guia para quem estÃ¡ comeÃ§ando no kafka.

Para subir o kafka na nossa mÃ¡quina, estamos utilizando o docker-compose, navegue atÃ© a pasta Docker e dentro dela vocÃª encontrarÃ¡ o zk-single-kafka-single.yml. 

Esse yaml foi criado pela Conduktor e existem mais opÃ§Ãµes aqui [link](https://www.conduktor.io/kafka/complete-kafka-producer-with-java/). NÃ³s subiremos apenas 1 kafka broker, 1 zookeper e 1 topico apenas.

> docker-compose -f zk-single-kafka-single up -d

# Consumidor kafka via CLI 

ApÃ³s executar e subir o Kafka acima, vocÃª pode subir um consumer via CLI, ou pelo ConsumerDemo.

> kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic demo_java 

# Principais TÃ³picos

O Apache Kafka Ã© uma plataforma de streaming distribuÃ­da e de cÃ³digo aberto projetada para construir pipelines de dados em tempo real e aplicativos de streaming.

O Kafka opera como um **sistema de mensagens pub-sub distribuÃ­do**, permitindo que aplicaÃ§Ãµes publiquem e assinem feeds de dados em tempo real ou quase em tempo real. **A alta taxa de transferÃªncia, escalabilidade, tolerÃ¢ncia a falhas, durabilidade e ecossistema que o Kafka oferece o tornaram uma escolha muito popular para casos de uso que exigem feeds de dados em tempo real**.

**Os principais componentes do Kafka incluem**:

ğŸ”¸ **Produtor**

Produtores publicam (escrevem) mensagens para um tÃ³pico do Kafka.

ğŸ”¸ **Consumidor**

Consumidores/assinantes assinam tÃ³picos e processam (leem) o fluxo de mensagens publicadas.

ğŸ”¸ **Broker**

Brokers sÃ£o servidores Kafka que armazenam dados e atendem clientes. VÃ¡rios brokers formam um cluster.

ğŸ”¸ **TÃ³pico**

TÃ³picos sÃ£o um nome de feed ou categoria de mensagens para as quais os produtores publicam mensagens.

ğŸ”¸ **PartiÃ§Ã£o**

As mensagens sÃ£o organizadas em tÃ³picos, que podem ser ainda mais divididos em partiÃ§Ãµes. Isso aumenta o paralelismo e a escalabilidade, permitindo que consumidores leiam diferentes partiÃ§Ãµes ao mesmo tempo.

**O Kafka pode ser usado para muitos casos de uso. Alguns dos casos de uso mais comuns incluem**:

ğŸ”¹ **AgregaÃ§Ã£o de dados de diferentes fontes**: Seja em pipelines ETL, lakes de dados ou agregaÃ§Ã£o de logs; ingerir, organizar, transformar e distribuir dados sÃ£o funÃ§Ãµes principais do Kafka.

ğŸ”¹ **Processamento de streams**: O Kafka pode ser usado para construir aplicativos de anÃ¡lise em tempo real.

ğŸ”¹ **Processamento de eventos**: Sistemas ou aplicativos que dependem do processamento de eventos em tempo real, como dispositivos IoT.

ğŸ”¹ **Monitoramento**: O Kafka Ã© bem adequado para armazenar logs e mÃ©tricas, permitindo monitoramento e alertas em tempo real.

Projetado para tolerÃ¢ncia a falhas, alta taxa de transferÃªncia, durabilidade e escalabilidade, o Kafka serve como um serviÃ§o intermediÃ¡rio para lidar com grandes volumes de dados. Embora o Kafka ofereÃ§a muitas vantagens para construir pipelines de dados em tempo real e aplicativos de streaming, ele tambÃ©m traz algumas desvantagens, sendo a mais notÃ¡vel a complexidade adicional que adiciona Ã  arquitetura do sistema. Dito isso, se um feed de dados em tempo real for necessÃ¡rio, o Kafka Ã© uma escolha popular.


# Como o kafka Funciona (gif by levelupcoding.com):
![kafka-visual-guide.gif](kafka-basics%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbrunobarros2093%2Fdemos%2Fpublic%2Fkafka-visual-guide.gif)
